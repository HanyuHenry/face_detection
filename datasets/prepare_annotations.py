import os
import json
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent
TXT_PATH = BASE_DIR / "datasets" / "raw" / "wider_face_train_bbx_gt.txt"
IMG_DIR = BASE_DIR / "datasets" / "raw" / "images"
OUTPUT_PATH = BASE_DIR / "datasets" / "annotations.json"

def prepare_annotations(txt_path, img_dir, output_path):
    with open(txt_path, "r", encoding="utf-8") as f:
        lines = f.read().splitlines()

    data = []
    i = 0
    missing = 0
    skipped = 0

    while i < len(lines):
        filename = lines[i].strip()
        if not filename.endswith(".jpg"):
            i += 1
            continue

        i += 1
        if i >= len(lines):
            break

        try:
            num_faces = int(lines[i].strip())
        except ValueError:
            print(f"âš ï¸  è·³è¿‡æ— æ•ˆè®°å½•ï¼ˆæ— æ³•è§£æäººè„¸æ•°é‡ï¼‰: {filename}")
            skipped += 1
            continue

        i += 1
        boxes = []

        for _ in range(num_faces):
            if i >= len(lines): break
            parts = lines[i].strip().split()
            if len(parts) >= 4:
                try:
                    x, y, w, h = map(int, parts[:4])
                    if w > 10 and h > 10:
                        boxes.append({"x": x, "y": y, "w": w, "h": h})
                except:
                    pass
            i += 1

        img_path = IMG_DIR / filename
        if img_path.exists() and boxes:
            data.append({"filename": filename, "boxes": boxes})
        elif not img_path.exists():
            missing += 1
            print(f"âŒ å›¾åƒä¸å­˜åœ¨ï¼Œè·³è¿‡: {filename}")

    with open(output_path, "w") as f:
        json.dump(data, f, indent=2)

    print(f"\nâœ… è½¬æ¢å®Œæˆ")
    print(f"ğŸ“Š æœ‰æ•ˆå›¾åƒ: {len(data)}")
    print(f"âŒ ç¼ºå¤±å›¾åƒ: {missing}")
    print(f"âš ï¸ æ ¼å¼è·³è¿‡: {skipped}")
    print(f"ğŸ“„ è¾“å‡ºè·¯å¾„: {output_path}")

if __name__ == "__main__":
    prepare_annotations(TXT_PATH, IMG_DIR, OUTPUT_PATH)
