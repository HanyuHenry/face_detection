import sys
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parent.parent))  # âœ… æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„

import torch
from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor
from torch.amp import autocast, GradScaler
from torchvision.ops import nms
from tqdm import tqdm
import matplotlib.pyplot as plt
from PIL import Image
import random
import json

from models.face_model import get_face_detector
from scripts.face_dataset import FaceDetectionDataset

def collate_fn(batch):
    return tuple(zip(*batch))

# âœ… å¯è§†åŒ–é¢„æµ‹ç»“æœï¼ˆåŒ…å« NMS + çœŸå®æ¡†ï¼‰
def visualize_predictions(model, all_image_paths, device, annotation_path=None):
    if not all_image_paths:
        print("âš ï¸ æ— æµ‹è¯•å›¾åƒï¼Œè·³è¿‡å¯è§†åŒ–")
        return

    image_paths = random.sample(all_image_paths, min(3, len(all_image_paths)))

    annotations = {}
    if annotation_path and Path(annotation_path).exists():
        with open(annotation_path, "r") as f:
            data = json.load(f)
            annotations = {item["filename"]: item["boxes"] for item in data}

    model.eval()
    transform = ToTensor()
    fig, axs = plt.subplots(1, len(image_paths), figsize=(5 * len(image_paths), 5))
    if len(image_paths) == 1:
        axs = [axs]

    for idx, img_path in enumerate(image_paths):
        try:
            img = Image.open(img_path).convert("RGB")
            tensor_img = transform(img).to(device)

            with torch.no_grad():
                prediction = model([tensor_img])[0]

            boxes = prediction['boxes'].cpu()
            scores = prediction['scores'].cpu()

            keep = nms(boxes, scores, iou_threshold=0.3)
            boxes = boxes[keep]
            scores = scores[keep]

            axs[idx].imshow(img)

            CONF_THRESH = 0.5
            for box, score in zip(boxes, scores):
                if score >= CONF_THRESH:
                    x1, y1, x2, y2 = box
                    axs[idx].add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,
                                                     edgecolor='r', facecolor='none', linewidth=2))

            try:
                relative_path = str(img_path.relative_to(Path(__file__).resolve().parent / "datasets" / "raw" / "images")).replace("\\", "/")
                for gt in annotations.get(relative_path, []):
                    x, y, w, h = gt['x'], gt['y'], gt['w'], gt['h']
                    axs[idx].add_patch(plt.Rectangle((x, y), w, h,
                                                     edgecolor='blue', facecolor='none', linewidth=2))
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡çœŸå®æ¡†æ ‡æ³¨åŠ è½½å¤±è´¥: {e}")

            axs[idx].set_title(f"Image {idx+1}")
            axs[idx].axis('off')

        except Exception as e:
            print(f"âš ï¸ è·³è¿‡å›¾åƒ {img_path.name}ï¼ŒåŸå› : {e}")

    plt.tight_layout()
    plt.show()

def main():
    data_limit = None # è®¾ç½®ä¸º None ä»¥ä½¿ç”¨æ‰€æœ‰æ•°æ®ï¼Œæˆ–è®¾ç½®ä¸ºæ•´æ•°ä»¥é™åˆ¶æ ·æœ¬æ•°
    print("ğŸš€ å¼€å§‹è®­ç»ƒäººè„¸æ£€æµ‹æ¨¡å‹...")
    torch.backends.cudnn.benchmark = True
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸš€ ä½¿ç”¨è®¾å¤‡ï¼š{device}")

    BASE_DIR = Path(__file__).resolve().parent.parent
    CHECK_DIR = BASE_DIR / "Checks"
    CHECK_DIR.mkdir(exist_ok=True)
    CHECKPOINT_PATH = BASE_DIR / "checkpoint.pt"
    BEST_MODEL_PATH = BASE_DIR / "best_model.pt"
    IMG_DIR = BASE_DIR / "datasets" / "raw" / "images"
    ANN_PATH = BASE_DIR / "datasets" / "annotations.json"

    all_images = list(IMG_DIR.rglob("*.jpg"))

    transform = ToTensor()
    full_dataset = FaceDetectionDataset(str(IMG_DIR), str(ANN_PATH), transform=transform, resize=(640, 640))
    dataset = full_dataset if data_limit is None else torch.utils.data.Subset(
        full_dataset, random.sample(range(len(full_dataset)), data_limit)
    )
    dataloader = DataLoader(dataset, 
                            batch_size=6, 
                            shuffle=True, 
                            num_workers=4,
                            pin_memory=True, 
                            collate_fn=collate_fn)

    model = get_face_detector(num_classes=2).to(device)
    optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.0001)
    scaler = GradScaler(device='cuda')
    start_epoch = 0
    best_loss = float('inf')

    if CHECKPOINT_PATH.exists():
        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch']
        print(f"\nğŸ”„ ç»§ç»­è®­ç»ƒï¼šä»ç¬¬ {start_epoch} è½®æ¢å¤")

        # âœ… å¦‚æœå­˜åœ¨ best modelï¼ŒåŠ è½½å…¶ loss
        if BEST_MODEL_PATH.exists():
            best_model_state = torch.load(BEST_MODEL_PATH, map_location=device)
            model.eval()
            with torch.no_grad():
                val_loss = 0.0
                for images, targets in dataloader:
                    images = [img.to(device) for img in images]
                    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
                    loss_dict = model(images, targets)
                    val_loss += sum(loss for loss in loss_dict.values()).item()
                best_loss = val_loss
                print(f"âœ… å·²æ¢å¤å†å²æœ€ä½³æ¨¡å‹ Loss: {best_loss:.4f}")
    else:
        print("\nğŸ†• ä»å¤´å¼€å§‹è®­ç»ƒ")

    print(f"ğŸ“Š å½“å‰æ ·æœ¬æ•°: {len(dataset)}ï¼Œæ¯è½® batch æ•°: {len(dataloader)}\n")

    epochs = 100
    for epoch in range(start_epoch, epochs):
        model.train()
        total_loss = 0.0
        progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")

        for images, targets in progress_bar:
            try:
                images = [img.to(device) for img in images]
                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

                with autocast(device_type='cuda'):
                    loss_dict = model(images, targets)
                    losses = sum(loss for loss in loss_dict.values())

                optimizer.zero_grad()
                scaler.scale(losses).backward()
                scaler.step(optimizer)
                scaler.update()

                total_loss += losses.item()
                progress_bar.set_postfix(loss=losses.item())

            except Exception as e:
                print(f"âš ï¸ è·³è¿‡å¼‚å¸¸ batch: {e}")
                continue

        print(f"ğŸ“˜ Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}")

        if (epoch + 1) % 5 == 0:
            torch.save(model.state_dict(), CHECK_DIR / f"backup_epoch_{epoch+1}.pt")    

        torch.save({
            'model': model.state_dict(),
            'optimizer': optimizer.state_dict(),
            'epoch': epoch + 1
        }, CHECKPOINT_PATH)

        if total_loss < best_loss:
            best_loss = total_loss
            torch.save(model.state_dict(), BEST_MODEL_PATH)
            print(f"â­ ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆloss: {best_loss:.4f}ï¼‰")

    print("\nâœ… è®­ç»ƒå®Œæˆå¹¶å·²ä¿å­˜æ¨¡å‹")

if __name__ == "__main__":
    import multiprocessing
    multiprocessing.freeze_support()
    main()
